{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1875, 'Formula 1', 'Formula 1 Circle Jerk'], [0.05405405405405406, 'r/de - Extraordinär gut!', 'Triff interessante Leute und frage ihnen Löcher in den Bauch!'], [0.13793103448275862, 'r/Apple - Unofficial Subreddit', 'Apple TV'], [0.0625, 'Canada', 'We are here for you. :)'], [0.125, 'Late Stage Capitalism', 'Late Stage Gender Binary']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import itertools\n",
    "import psycopg2\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(database = \"postgres\", user = \"postgres\", password = \"326935\", host = \"localhost\", port = \"5432\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Get the subreddit data\n",
    "def get_subreddits(): \n",
    "    cursor.execute(\"SELECT title, title, display_name, advertiser_category, public_description FROM reddit_recommender.subreddits\")\n",
    "    subreddits = cursor.fetchall()\n",
    "    return subreddits \n",
    "    \n",
    "def flatten(list):\n",
    "  for i in list:\n",
    "    for j in i:\n",
    "      yield j\n",
    "\n",
    "def get_jaccard_sim(subreddit1, subreddit2):\n",
    "    a = set(subreddit1)\n",
    "    b = set(subreddit2)\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def filterWords(text):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    unwantedWords = ['None','Impressum', 'impressum', 'r']\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    wordsFiltered = []\n",
    "    wordsFiltered = [word for word in words if word not in stopWords]\n",
    "    removeUnwanted = [word for word in wordsFiltered if word not in unwantedWords]\n",
    "    return removeUnwanted\n",
    "    \n",
    "def preprocess(subreddits):\n",
    "    subredditWordsList = []\n",
    "    for subreddit in range(len(subreddits)):\n",
    "        for word in subreddits: \n",
    "            subredditWordsList.append(filterWords(str(word)))\n",
    "        flattenWordsList = list(set(flatten(subredditWordsList))) \n",
    "    return flattenWordsList\n",
    "\n",
    "def compareSubreddits_bck(subreddit1, subreddit2): \n",
    "    subreddit1_pre = preprocess(subreddit1[1:])\n",
    "    subreddit2_pre = preprocess(subreddit2[1:])\n",
    "    similarity_score = get_jaccard_sim(subreddit1_pre, subreddit2_pre)\n",
    "    return similarity_score\n",
    "\n",
    "def compareSubreddits(subreddit1, subreddit2): \n",
    "    subreddit1_pre = preprocess(subreddit1[1:])\n",
    "    subreddit2_pre = subreddit2[1:]\n",
    "    similarity_score = get_jaccard_sim(subreddit1_pre, subreddit2_pre)\n",
    "    return similarity_score\n",
    "\n",
    "def search_recommendations_bck(user_subs, all_subreddits):\n",
    "    best_matches = []\n",
    "    for sub in user_subs:\n",
    "        result = []\n",
    "        best_match = 0.0\n",
    "        sub_id = sub[0]\n",
    "        match_id = 'id'\n",
    "        for subreddit in all_subreddits:\n",
    "            print(subreddit)\n",
    "            score = compareSubreddits_bck(sub, subreddit)\n",
    "            if(score > best_match and score < 1.0):\n",
    "                best_match = score\n",
    "                match_id = subreddit[0]\n",
    "        result.append(best_match)\n",
    "        result.append(sub_id)\n",
    "        result.append(match_id)\n",
    "        best_matches.append(result)        \n",
    "    return best_matches\n",
    "\n",
    "def search_recommendations(user_subs):\n",
    "    best_matches = [] \n",
    "    with open (\"../app/output_subreddits_words_list.pkl\", \"rb\") as fp:\n",
    "        itemlist = pickle.load(fp)\n",
    "        for sub in user_subs:\n",
    "            result = []\n",
    "            best_match = 0.0\n",
    "            sub_id = sub[0]\n",
    "            match_id = 'id'\n",
    "            for subreddit in itemlist:\n",
    "                score = compareSubreddits(sub, subreddit)\n",
    "                if(score > best_match and score < 1.0):\n",
    "                    best_match = score\n",
    "                    match_id = subreddit[0]\n",
    "            result.append(best_match)\n",
    "            result.append(sub_id)\n",
    "            result.append(match_id)\n",
    "            best_matches.append(result)        \n",
    "    return best_matches\n",
    "\n",
    "def append_subreddits_to_file(subreddits):\n",
    "    all = []\n",
    "    with open(\"../app/output_subreddits_words_list.pkl\", \"wb\") as fp:\n",
    "        for sub in subreddits:\n",
    "            liste = preprocess(sub)\n",
    "            liste.insert(0, sub[0])\n",
    "            all.append(liste)\n",
    "            #flattenWordsList.append(preprocess(sub))\n",
    "        pickle.dump(all, fp)\n",
    "    fp.close()\n",
    "\n",
    "    \n",
    "#alt\n",
    "subreddits = get_subreddits()\n",
    "user_subs = subreddits[100:105]\n",
    "result = search_recommendations(user_subs)\n",
    "print(result)\n",
    "#append_subreddits_to_file(subreddits)\n",
    "\n",
    "\n",
    "#with open (\"../app/output_subreddits_words_list.pkl\", \"rb\") as fp:\n",
    "#    itemlist = pickle.load(fp)\n",
    "#    print(itemlist)\n",
    "                \n",
    "cursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
